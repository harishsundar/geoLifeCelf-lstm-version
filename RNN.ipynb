{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T18:51:32.491909Z",
     "start_time": "2018-04-19T18:50:32.237312Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from multiprocessing import Pool\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from collections import OrderedDict\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model, save_model\n",
    "os.chdir(\"D:\\\\fyp\\Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:08:40.025566Z",
     "start_time": "2018-04-19T17:08:39.999332Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:]\n",
    "                        for file_name in batch_x]), np.array(batch_y)      \n",
    "\n",
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        \n",
    "        self.path = directory\n",
    "      #  df = pd.read_csv(\"occurrences_train.csv\",low_memory=False)\n",
    "        with open(\"D:\\\\fyp\\Dataset\\\\save.pkl\",\"rb\") as f:\n",
    "            hd = pkl.load(f)\n",
    "        with open(\"D:\\\\fyp\\Dataset\\\\save_test.pkl\",\"rb\") as f:\n",
    "            hdt = pkl.load(f)\n",
    "        self.train_metadata_y=[]\n",
    "        self.train_pathdata_x = []\n",
    "        self.train_seq_y = []\n",
    "        self.test_pathdata_x = []\n",
    "        self.test_seq_y = []\n",
    "        for extra in hd.keys():\n",
    "            for cls in hd[extra].keys():\n",
    "                for order in hd[extra][cls].keys():\n",
    "                    for family in hd[extra][cls][order].keys():\n",
    "                        for genus in hd[extra][cls][order][family].keys():\n",
    "                            for specie in hd[extra][cls][order][family][genus]:\n",
    "                                path=self.path+\"\\\\\"+cls+\"\\\\\"+order+\"\\\\\"+family+\"\\\\\"+genus+\"\\\\\"+specie\n",
    "                              #  print(path)\n",
    "                                for im in os.listdir(path):\n",
    "                                    self.train_pathdata_x.append(path+\"\\\\\"+im)\n",
    "  \n",
    "        \n",
    "        \n",
    "        np.random.shuffle(self.train_pathdata_x)\n",
    "   \n",
    "        self.classes=list(range(0, 768))\n",
    "        for p in self.train_pathdata_x:\n",
    "            y = p.split(\"\\\\\")\n",
    "            c = y[3]\n",
    "            o = y[4]\n",
    "            f = y[5]\n",
    "            g = y[6]\n",
    "            s = y[7]\n",
    "            self.train_seq_y.append(np.array([[c],[o],[f],[g],[s]]))\n",
    "        \n",
    "\n",
    "            \n",
    "    \n",
    "            \n",
    "    def model_create(self):\n",
    "        \n",
    "        classifier = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=96, kernel_size=(2, 2), activation = 'relu'), input_shape=(5,32,32,33)))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=256, kernel_size=(2, 2), activation = 'relu')))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=256, kernel_size=(3, 3), activation = 'relu')))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=512, kernel_size=(3, 3), activation = 'relu')))\n",
    "        #classifier.add(Conv2D(filters=, kernel_size=(2, 2), activation = 'relu'))\n",
    "        classifier.add(TimeDistributed(MaxPool2D(pool_size = (2, 2))))\n",
    "        # Step 3 - Flattening\n",
    "        classifier.add(TimeDistributed(Flatten()))\n",
    "        # Step 4 - LSTM\n",
    "        print(classifier.output_shape)\n",
    "      #  classifier.add(Reshape((1,432640)))\n",
    "        classifier.add(LSTM(100, return_sequences=True))\n",
    "        # Step 5 - Full connection\n",
    "        classifier.add(Dense(768, activation = 'relu'))\n",
    "        # Compiling the CNN\n",
    "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "        classifier.summary()\n",
    "        return classifier\n",
    "    \n",
    "    def fit_generator(self, num_epochs=10, batch_size=32, crop_size=16):        \n",
    "    \n",
    "        classifier = self.model_create()\n",
    "        train_data = ImageDataGenerator(self.train_pathdata_x,self.train_pathdata_x, 64, 16)\n",
    "        history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=False,shuffle=True)\n",
    "        classifier.save(\"D:\\\\fyp\\\\Dataset\\\\code\\\\Models\\\\RNN_5.h5\")\n",
    "\n",
    "        scores = classifier.evaluate_generator(train_data, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T17:08:49.868655Z",
     "start_time": "2018-04-19T17:08:40.870674Z"
    }
   },
   "outputs": [],
   "source": [
    "ob = CNN_Model(\"D:\\\\fyp\\\\Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=load_model(\"D:\\\\fyp\\CNN_data\\Selected\\Code\\Models\\RNN_Model5.h5\")\n",
    "batch_x=[\"D:\\\\fyp\\CNN_data\\Selected\\patchTrain\\Anacamptis pyramidalis\\\\patch_30.tif\"]\n",
    "def preprocess(): \n",
    "    return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int),\n",
    "                                     (1,2,0))[16:-16,16:-16,:]\n",
    "                        for file_name in batch_x])     \n",
    "predictions=preprocess()\n",
    "probabilities= model.predict(predictions)\n",
    "print(probabilities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Mean reciprocal rank= 0.0031987575309562165\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"D:\\\\fyp\\CNN_data\\\\Selected\\Code\\Models\\RNN_model1.h5\")\n",
    "def preprocess(imgpath): \n",
    "    return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int),\n",
    "                                     (1,2,0))[16:-16,16:-16,:]\n",
    "                        for file_name in imgpath])    \n",
    "path=\"D:\\\\fyp\\CNN_data\\\\patchTrain\"\n",
    "summation =0 ;\n",
    "a=[]\n",
    "correct_prob=0\n",
    "counter=0;\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "\n",
    "    folder_path=path+\"\\\\\"+folder;\n",
    "    for next_path in os.listdir(folder_path):\n",
    "        img_path= folder_path+\"\\\\\"+next_path\n",
    "        batch_x=[img_path];\n",
    "        predictions=preprocess(batch_x)\n",
    "        probabilities= model.predict(predictions)\n",
    "        a=probabilities[0].tolist()\n",
    "        correct_prob=a[counter]\n",
    "        a.sort()\n",
    "        rank=a.index(correct_prob)\n",
    "        rank+=1;\n",
    "        summation+=1/rank\n",
    "    counter+=1\n",
    "print(\"Mean reciprocal rank=\", summation/3524)  #Total number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reciprocal rank= 0.22580767289247805\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"D:\\\\fyp\\CNN_data\\\\Selected\\Code\\Models\\RNN_model5.h5\")\n",
    "def preprocess(imgpath): \n",
    "    return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int),\n",
    "                                     (1,2,0))[16:-16,16:-16,:]\n",
    "                        for file_name in imgpath])    \n",
    "path=\"D:\\\\fyp\\CNN_data\\Selected\\\\patchTrain\"\n",
    "summation =0 ;\n",
    "a=[]\n",
    "correct_prob=0\n",
    "counter=0;\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "\n",
    "    folder_path=path+\"\\\\\"+folder;\n",
    "    for next_path in os.listdir(folder_path):\n",
    "        img_path= folder_path+\"\\\\\"+next_path\n",
    "        batch_x=[img_path];\n",
    "        predictions=preprocess(batch_x)\n",
    "        probabilities= model.predict(predictions)\n",
    "        a=probabilities[0].tolist()\n",
    "        correct_prob=a[counter]\n",
    "        a.sort()\n",
    "        rank=a.index(correct_prob)\n",
    "        rank+=1;\n",
    "        summation+=1/rank\n",
    "    counter+=1\n",
    "print(\"Mean reciprocal rank=\", summation/566)  #Total number of images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
